# CUK_NL_team3
2025-2 Natural Language Processing term project by team 3

# 1. Project Overview

ë³¸ í”„ë¡œì íŠ¸ëŠ” ëª…ì‹œì (explicit) í•™ìŠµ / ì•”ì‹œì (implicit) í•™ìŠµ / In-Context Learning(ICL) ì¡°ê±´ì´
GPT2 ê¸°ë°˜ ì–¸ì–´ëª¨ë¸ì˜ ê·œì¹™ ë‚´ì¬í™” ëŠ¥ë ¥ ë° ì¼ë°˜í™” ëŠ¥ë ¥ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ë¹„êµí•˜ëŠ” ì‹¤í—˜ì´ë‹¤.

ì´ 3ê°œì˜ ì‹¤í—˜ìœ¼ë¡œ êµ¬ì„±ëœë‹¤:

1. E1 â€” Fine-tuning Efficiency

2. E2 â€” Grammaticality Judgment

  - BLiMP-style (ë¬¸ë²•ì„± íŒë‹¨, minimal pairs)

  - 5ì§€ì„ ë‹¤ ë¬¸ë²• íŒë‹¨

  - Surprisal Peak Plot (ë¬¸ë²• ì˜¤ë¥˜ ìœ„ì¹˜ localizing)

  - Prompting variation (explicit-card / explicit-explanation / implicit)

3. E3 â€” In-context Generalization (0,1,2,4-shot ICL)

# 2. Repository Structure

zipì—ì„œ í™•ì¸í•œ êµ¬ì¡°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ main ê¸°ì¤€ìœ¼ë¡œ ì´ë¯¸ ì •ë¦¬ëœ í˜•íƒœë¡œ ë¬¸ì„œí™”í–ˆìŒ.
feat# í´ë”ëŠ” ì‹¤í—˜ ì¤‘ê°„ ì‚°ì¶œë¬¼ì´ë©°, ìµœì¢… ì½”ë“œëŠ” main/ í•˜ìœ„ì— í†µí•©ëœë‹¤ëŠ” ê°€ì •ìœ¼ë¡œ ì •ë¦¬.

main/
â”‚
â”œâ”€â”€ config/                      # ì‹¤í—˜ ì„¤ì • YAML
â”‚   â”œâ”€â”€ base.yaml
â”‚   â”œâ”€â”€ explicit.yaml
â”‚   â””â”€â”€ implicit.yaml
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ dataset.zip              # ENG / ArLang paired datasets
â”‚   â””â”€â”€ split.py                 # train/valid/test split + OOD generation
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ artlang_generator.py     # ì¸ê³µì–¸ì–´(SOV) ìƒì„±ê¸°
â”‚   â”œâ”€â”€ build_datasets.py        # Explicit / Implicit dataset builder
â”‚   â”œâ”€â”€ create_pairs.py          # OK / Violation minimal pairs ìƒì„±
â”‚   â”œâ”€â”€ dataloader.py            # PyTorch Dataset/Loader
â”‚   â”œâ”€â”€ model.py                 # GPT2 ê¸°ë°˜ LM wrapper
â”‚   â”œâ”€â”€ prompts.py               # Prompt templates (explicit/implicit)
â”‚   â”œâ”€â”€ run_ft.py                # Fine-tuning ì‹¤í–‰ (E1)
â”‚   â”œâ”€â”€ run_eval_e2.py           # E2 BLiMP/PLL/5ì§€ì„ ë‹¤/Surprisal
â”‚   â”œâ”€â”€ run_icl.py               # E3 ICL 0â€“4 shot evaluation
â”‚   â””â”€â”€ utils.py                # ê³µí†µ í•¨ìˆ˜ (tokenizer, logger, seed)
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ train.py                 # E1 í•™ìŠµ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
â”‚   â”œâ”€â”€ evaluate_methods2.py     # E2 ì‹¤í–‰
â”‚   â”œâ”€â”€ plot_learning_curves.py  # E1 PPL ê·¸ë˜í”„ ìƒì„±
â”‚   â””â”€â”€ plot_surprisal.py        # E2 surprisal ì‹œê°í™”
â”‚
â””â”€â”€ utils/
    â”œâ”€â”€ metrics.py               # PLL, accuracy, surprisal ê³„ì‚°
    â””â”€â”€ helpers.py               # íŒŒì¼ ì²˜ë¦¬, config loader

#ï¸âƒ£ 3. Installation
conda create -n nlproj python=3.10
conda activate nlproj
pip install -r requirements.txt


ì£¼ìš” íŒ¨í‚¤ì§€:

PyTorch

Transformers

SentencePiece

matplotlib / seaborn

pandas

#ï¸âƒ£ 4. Dataset Preparation
1) Artificial Language (ArLa)

Zipf ê¸°ë°˜ ì–´íœ˜ ìƒ˜í”Œë§

ê·œì¹™ ê¸°ë°˜ SOV ìƒì„±

OK / Violation minimal pairs ìƒì„±

2) English (SVO)

Simple English Wikipedia ê¸°ë°˜

SpaCy ì˜ì¡´êµ¬ë¬¸ í•„í„°ë§

SVO ë¬¸ì¥ë§Œ ì¶”ì¶œ í›„ minimal pair ìƒì„±

ë°ì´í„° ì¤€ë¹„ ì‹¤í–‰
python src/build_datasets.py --config config/base.yaml
python src/create_pairs.py
python data/split.py

#ï¸âƒ£ 5. Experiments
ğŸ”µ E1 â€” Fine-tuning Efficiency
ëª©ì 

Explicit vs Implicit í•™ìŠµ ì¡°ê±´ì—ì„œ GPT2ê°€ ì–¼ë§ˆë‚˜ ë¹ ë¥´ê³  ì•ˆì •ì ìœ¼ë¡œ ê·œì¹™ì— ì ì‘í•˜ëŠ”ê°€(PPL ìˆ˜ë ´) ë¹„êµ.

ì‹¤í–‰
python scripts/train.py --config config/explicit.yaml
python scripts/train.py --config config/implicit.yaml

ì¶œë ¥ë¬¼

outputs/e1/logs/

outputs/e1/ppl_curves.png

ğŸŸ£ E2 â€” Grammaticality Judgment (ì—¬ëŸ¬ ë²„ì „ í¬í•¨)
í¬í•¨ëœ í•˜ìœ„ ì‹¤í—˜

BLiMP-style (minimal pair PLL ranking)

5ì§€ì„ ë‹¤ ë¬¸ë²• íŒë‹¨

Surprisal Peak Plot â€” ë¬¸ë²• ì˜¤ë¥˜ê°€ ë°œìƒí•˜ëŠ” ì§€ì ì˜ surprisal ìƒìŠ¹ ì²´í¬

Prompt variation tuning

explicit-card (â€œê·œì¹™ì¹´ë“œâ€)

explicit-explanation (â€œì„¤ëª…í˜•â€)

implicit (â€œë¬¸ì¥ë§Œ ì œì‹œâ€)

ì‹¤í–‰
python src/run_eval_e2.py

ì¶œë ¥ë¬¼

outputs/e2/accuracy.csv

outputs/e2/surprisal_plots/*.png

outputs/e2/multiple_choice_results.json

ğŸŸ¢ E3 â€” In-context Learning (0/1/2/4-shot)
ëª©ì 

í•™ìŠµëœ ëª¨ë¸ì´ ë¬¸ë§¥ë§Œ ë³´ê³  ê·œì¹™ì„ ì¶”ë¡ í•  ìˆ˜ ìˆëŠ”ì§€ í™•ì¸.

ì‹¤í–‰
python src/run_icl.py --shots 0
python src/run_icl.py --shots 1
python src/run_icl.py --shots 2
python src/run_icl.py --shots 4

#ï¸âƒ£ 6. Results Overview

(ìì„¸í•œ ìˆ˜ì¹˜ëŠ” Evaluation Reportì—ì„œ ì œê³µ)

E1: explicit ì¡°ê±´ì€ ì´ˆê¸° ìˆ˜ë ´ì´ ë¹ ë¥´ê³ , implicit ì¡°ê±´ì€ ì•ˆì •ì ì´ë©° ìì—°ìŠ¤ëŸ¬ìš´ ê·œì¹™ ë‚´ì¬í™” ê²½í–¥

E2: Prompting ì œê³µ ì—¬ë¶€ê°€ ë¬¸ë²•ì„± íŒë‹¨ ì •í™•ë„ì— í° ì˜í–¥

E3: implicit í•™ìŠµ ëª¨ë¸ì€ ICLì—ì„œ ì„±ëŠ¥ì´ ë” ìƒìŠ¹í•˜ëŠ” ê²½í–¥

#ï¸âƒ£ 7. Reproducibility

ëª¨ë“  ì‹¤í—˜ì€ seed ê³ ì •

config íŒŒì¼ ê¸°ë°˜ìœ¼ë¡œ ì‹¤í—˜ ë°˜ë³µ ê°€ëŠ¥

ë°ì´í„° ê²½ë¡œëŠ” config/*.yamlì—ì„œ ìˆ˜ì • ê°€ëŠ¥

#ï¸âƒ£ 8. Contributors (Team 3 / ê°€í†¨ë¦­ëŒ€í•™êµ)

ğŸ“Œ E1 / E2(implicitâ€“explicit prompting) â€” ìœ ì§„ë‹˜

ğŸ“Œ E2(BLiMP / 5ì§€ì„ ë‹¤ / Surprisal) â€” í•œì¢…ë‹˜

ğŸ“Œ E1 / ArLa generation / infrastructure â€” í™í‚¤ì¿ í‚¤ì¿ 

ğŸ“Œ Code integration & documentation â€” ì „ì› ê¸°ì—¬

#ï¸âƒ£ 9. License

MIT License (í•„ìš”ì‹œ)
