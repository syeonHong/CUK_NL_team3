# CUK_NL_team3
2025-2 Natural Language Processing term project by team 3

**NOTE: ì¤‘ê°„ì¤‘ê°„ ê²°ê³¼ Graph ì‚½ì… ì˜ˆì • **


## #ï¸âƒ£ 1. Project Overview

ë³¸ í”„ë¡œì íŠ¸ëŠ” GPT2 ê¸°ë°˜ ì–¸ì–´ëª¨ë¸ì„ ëŒ€ìƒìœ¼ë¡œ
ëª…ì‹œì (explicit) / ì•”ì‹œì (implicit) í•™ìŠµ ë°©ì‹ / ICL(few-shot) ê°„
ê·œì¹™ ë‚´ì¬í™” ë° ì¼ë°˜í™” ëŠ¥ë ¥ì˜ ì°¨ì´ë¥¼ ë¶„ì„í•˜ëŠ” ì—°êµ¬ì´ë‹¤.

ì´ 3ê°œì˜ ë©”ì¸ ì‹¤í—˜:

- E1 â€” Fine-tuning Efficiency
- E2 â€” Grammaticality Judgment (ì—¬ëŸ¬ ë²„ì „ í¬í•¨)
- E3 â€” In-context Learning (0â€“4-shot)



## #ï¸âƒ£ 2. Repository Structure
```
main/
â”‚
â”œâ”€â”€ config/ # ì‹¤í—˜ êµ¬ì„± YAML
â”œâ”€â”€ data/ # dataset zip ë° split ì½”ë“œ
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ artlang_generator.py # ì¸ê³µì–¸ì–´ ìƒì„±ê¸°
â”‚ â”œâ”€â”€ build_datasets.py # ENG/SOV explicit/implicit dataset ìƒì„±
â”‚ â”œâ”€â”€ create_pairs.py # OK/Violation minimal pairs ìƒì„±
â”‚ â”œâ”€â”€ dataloader.py # PyTorch Dataset
â”‚ â”œâ”€â”€ model.py # GPT2 wrapper model
â”‚ â”œâ”€â”€ prompts.py # explicit/implicit prompt card
â”‚ â”œâ”€â”€ run_ft.py # E1 íŒŒì¸íŠœë‹ ì½”ë“œ
â”‚ â”œâ”€â”€ run_eval_e2.py # E2(BLiMP, 5-choice, surprisal)
â”‚ â”œâ”€â”€ run_icl.py # E3 ICL ì½”ë“œ
â”‚ â””â”€â”€ utils.py # ê³µí†µ í•¨ìˆ˜
â”‚
â”œâ”€â”€ scripts/ # ê·¸ë˜í”„, ê²°ê³¼ ì •ë¦¬ ìŠ¤í¬ë¦½íŠ¸
â””â”€â”€ utils/ # metrics ë° helper
```

## #ï¸âƒ£ 3. File Description

### Dataset ê´€ë ¨
- build_datasets.py â€” ì˜ì–´(SVO)Â·ì¸ê³µì–¸ì–´(SOV) ê¸°ë°˜ explicit/implicit ë°ì´í„° êµ¬ì„±  
- create_pairs.py â€” OK vs Violation minimal pairs ìƒì„±  
- split.py â€” train/dev/test + OOD split  

### Model ê´€ë ¨
- model.py â€” GPT2 LM + loss ê³„ì‚°  
- prompts.py â€” explicit-card, explicit-explanation, implicit prompt template  
- dataloader.py â€” tokenization & batch dataloader  

### Experiment ì½”ë“œ
- run_ft.py â€” E1 fine-tuning ë¡œì§  
- run_eval_e2.py â€” E2(ë¬¸ë²•ì„± íŒë‹¨) ëª¨ë“  ë²„ì „ í¬í•¨  
- run_icl.py â€” E3(0/1/2/4-shot ICL)  

### ì‹œê°í™”
- plot_learning_curves.py  
- plot_surprisal.py  



## #ï¸âƒ£ 4. Experiment Structure

### ğŸ”µ E1 â€” Fine-tuning Efficiency
- explicit vs implicit vs SVO vs SOV ì¡°ê±´ ê°„ PPL ìˆ˜ë ´ ë¹„êµ  
- output: loss/logs, PPL curves  

### ğŸŸ£ E2 â€” Grammaticality Judgment
í•˜ìœ„ êµ¬ì„±:
- BLiMP-style PLL ranking  
- 5-choice ë¬¸ë²• íŒë‹¨  
- Surprisal Peak Plot  
- Prompt variation (explicit-card, explicit-explanation, implicit)  
- output: accuracy, Î”PLL, surprisal ì‹œê°í™”  

### ğŸŸ¢ E3 â€” ICL (0â€“4 shot)
- í•™ìŠµ ì—†ì´ few-shot ë¬¸ë§¥ë§Œìœ¼ë¡œ ê·œì¹™ ì¶”ë¡ í•˜ëŠ”ì§€ í‰ê°€  
- output: shotë³„ accuracy curve  



## #ï¸âƒ£ 5. How Components Connect

- build_datasets.py â†’ create_pairs.py â†’ data/split.py  
- dataloader.py + model.py  
- E1/E2/E3 ì‹¤í–‰ ì½”ë“œê°€ ìœ„ ë¹Œë”© ë¸”ë¡ì„ ì¡°í•©  
- scripts/ í´ë”ê°€ ê²°ê³¼ë¥¼ ì •ë¦¬Â·ì‹œê°í™”  



## #ï¸âƒ£ 6. Team Members (Team 3 â€” ê°€í†¨ë¦­ëŒ€í•™êµ)

- Dataset / ArLa generation: ë¥˜ì¬í˜•
- E1 / E2 (ArLa): ì´ìœ ì§„
- E1 / E2 (Eng): ìµœí•œì¢…
- E3 (ArLa) : ì¥ì£¼ì€
- í†µí•© / ë¬¸ì„œí™” / êµ¬ì¡°í™”: í™ìŠ¹ì—°
